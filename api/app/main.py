import os
import asyncio
import json
import tempfile
import subprocess
from datetime import timedelta
from typing import Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from google.cloud import storage, aiplatform, secretmanager
from google.cloud.aiplatform_v1.types import CustomJobSpec, WorkerPoolSpec, MachineSpec, ContainerSpec
from sse_starlette.sse import EventSourceResponse

# ç’°å¢ƒå¤‰æ•°
PROJECT_ID = os.environ.get("PROJECT_ID", "encoded-victory-440718-k6")
REGION = os.environ.get("REGION", "us-west1")
BUCKET = os.environ.get("BUCKET", "audio-processing-studio")
WORKER_IMAGE_URI_GPU = os.environ.get("WORKER_IMAGE_URI_GPU")
WORKER_IMAGE_URI_CPU = os.environ.get("WORKER_IMAGE_URI_CPU")
# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€WORKER_IMAGE_URIãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
WORKER_IMAGE_URI = os.environ.get("WORKER_IMAGE_URI")
HF_TOKEN_SECRET = os.environ.get("MEETING_HF_TOKEN", "")

app = FastAPI(title="Meeting Audio Processing API")

# CORSè¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼šè¤‡æ•°ã‚ªãƒªã‚¸ãƒ³å¯¾å¿œï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001",
        "http://127.0.0.1:3001",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Vertex AI åˆæœŸåŒ–
aiplatform.init(
    project=PROJECT_ID, 
    location=REGION,
    staging_bucket=f"gs://{BUCKET}"
)

# GCS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
storage_client = storage.Client()


class SignUrlRequest(BaseModel):
    file_name: str
    content_type: str = "audio/wav"


class JobRequest(BaseModel):
    input_gs_uri: str
    output_gs_uri: Optional[str] = None
    use_gpu: bool = True


@app.get("/health")
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "ok", "project": PROJECT_ID, "region": REGION}


@app.post("/sign-url")
async def create_signed_url(request: SignUrlRequest):
    """GCSç½²åURLã‚’ç™ºè¡Œï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ç›´ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰"""
    try:
        import json
        from google.oauth2 import service_account
        
        # Secret Managerã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/run-api-service-account-key/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        secret_data = response.payload.data.decode("UTF-8")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        service_account_info = json.loads(secret_data)
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èªè¨¼æƒ…å ±ä»˜ãã§ä½œæˆ
        storage_client_with_key = storage.Client(credentials=credentials, project=PROJECT_ID)
        bucket = storage_client_with_key.bucket(BUCKET)
        blob = bucket.blob(f"uploads/{request.file_name}")
        
        # PUTç”¨ã®ç½²åURLï¼ˆ10åˆ†æœ‰åŠ¹ï¼‰
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=10),
            method="PUT",
            content_type=request.content_type
        )
        
        return {
            "signed_url": url,
            "gs_uri": f"gs://{BUCKET}/uploads/{request.file_name}",
            "expires_in": 600
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class DownloadUrlRequest(BaseModel):
    gs_uri: str


@app.post("/download-url")
async def create_download_url(request: DownloadUrlRequest):
    """GCSç½²åãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’ç™ºè¡Œ"""
    try:
        import json
        from google.oauth2 import service_account
        
        # gs:// ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¦ãƒ‘ã‚¹ã‚’å–å¾—
        if not request.gs_uri.startswith(f"gs://{BUCKET}/"):
            raise HTTPException(status_code=400, detail="Invalid GCS URI")
        
        blob_path = request.gs_uri.replace(f"gs://{BUCKET}/", "")
        
        # Secret Managerã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/run-api-service-account-key/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        secret_data = response.payload.data.decode("UTF-8")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        service_account_info = json.loads(secret_data)
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èªè¨¼æƒ…å ±ä»˜ãã§ä½œæˆ
        storage_client_with_key = storage.Client(credentials=credentials, project=PROJECT_ID)
        bucket = storage_client_with_key.bucket(BUCKET)
        blob = bucket.blob(blob_path)
        
        # GETç”¨ã®ç½²åURLï¼ˆ10åˆ†æœ‰åŠ¹ï¼‰
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=10),
            method="GET"
        )
        
        return {
            "signed_url": url,
            "expires_in": 600
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/jobs")
async def create_job(request: JobRequest):
    """Vertex AI Custom Jobï¼ˆGPUï¼‰ã‚’èµ·å‹•"""
    try:
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼šuse_gpu ã®å€¤ã‚’ç¢ºèª
        print(f"ğŸ” DEBUG: use_gpu = {request.use_gpu}")
        
        # å‡ºåŠ›å…ˆãŒæœªæŒ‡å®šãªã‚‰è‡ªå‹•ç”Ÿæˆ
        if not request.output_gs_uri:
            file_name = request.input_gs_uri.split("/")[-1].replace(".wav", ".json")
            request.output_gs_uri = f"gs://{BUCKET}/outputs/{file_name}"
        
        # Vertex AI Custom Job ã®å®šç¾©ï¼ˆGPU/CPUåˆ‡ã‚Šæ›¿ãˆï¼‰
        if request.use_gpu:
            print("âœ… GPU mode selected")
            # GPUä½¿ç”¨
            machine_spec = MachineSpec(
                machine_type="n1-standard-4",
                accelerator_type="NVIDIA_TESLA_T4",
                accelerator_count=1,
            )
            # GPUå°‚ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°æ±ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰
            image_uri = WORKER_IMAGE_URI_GPU or WORKER_IMAGE_URI
        else:
            print("ğŸ–¥ï¸ CPU mode selected")
            # CPUä½¿ç”¨ï¼ˆacceleratorãªã—ï¼‰
            machine_spec = MachineSpec(
                machine_type="n1-standard-4",
            )
            # CPUå°‚ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°æ±ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰
            image_uri = WORKER_IMAGE_URI_CPU or WORKER_IMAGE_URI
        
        if not image_uri:
            raise HTTPException(status_code=500, detail="WORKER_IMAGE_URI not configured")
        
        print(f"ğŸ“¦ Using image: {image_uri}")
        
        worker_pool_specs = [
            WorkerPoolSpec(
                machine_spec=machine_spec,
                replica_count=1,
                container_spec=ContainerSpec(
                    image_uri=image_uri,
                    args=[
                        "--input", request.input_gs_uri,
                        "--output", request.output_gs_uri,
                    ],
                    env=[
                        {"name": "MEETING_HF_TOKEN", "value": HF_TOKEN_SECRET}
                    ]
                ),
            )
        ]
        
        custom_job = aiplatform.CustomJob(
            display_name="pyannote-diarization",
            worker_pool_specs=worker_pool_specs,
        )
        
        # éåŒæœŸå®Ÿè¡Œ
        custom_job.submit()
        
        return {
            "job_id": custom_job.resource_name,
            "input": request.input_gs_uri,
            "output": request.output_gs_uri,
            "status": "SUBMITTED"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/events/{job_id:path}")
async def job_events(job_id: str):
    """SSEã§ã‚¸ãƒ§ãƒ–é€²æ—ã‚’é…ä¿¡"""
    async def event_generator():
        try:
            last_state = None
            while True:
                # ã‚¸ãƒ§ãƒ–IDã‹ã‚‰CustomJobã‚’å–å¾—ï¼ˆæ¯å›æœ€æ–°çŠ¶æ…‹ã‚’å–å¾—ï¼‰
                job = aiplatform.CustomJob.get(job_id)
                current_state = job.state.name
                
                if current_state != last_state:
                    # é€²æ—ã‚’æ¨å®š
                    progress = {
                        "JOB_STATE_QUEUED": 5,
                        "JOB_STATE_PENDING": 10,
                        "JOB_STATE_RUNNING": 50,
                        "JOB_STATE_SUCCEEDED": 100,
                        "JOB_STATE_FAILED": 0,
                        "JOB_STATE_CANCELLED": 0,
                    }.get(current_state, 0)
                    
                    yield {
                        "event": "progress",
                        "data": str(progress)
                    }
                    last_state = current_state
                
                # çµ‚äº†çŠ¶æ…‹ãªã‚‰å®Œäº†
                if current_state in ["JOB_STATE_SUCCEEDED", "JOB_STATE_FAILED", "JOB_STATE_CANCELLED"]:
                    yield {
                        "event": "complete",
                        "data": current_state
                    }
                    break
                
                await asyncio.sleep(2)
        except Exception as e:
            yield {
                "event": "error",
                "data": str(e)
            }
    
    return EventSourceResponse(event_generator())


@app.get("/jobs/{job_id:path}")
async def get_job_status(job_id: str):
    """ã‚¸ãƒ§ãƒ–çŠ¶æ…‹ã‚’å–å¾—"""
    try:
        # CustomJob.get() ã§æœ€æ–°çŠ¶æ…‹ã‚’å–å¾—
        job = aiplatform.CustomJob.get(job_id)
        
        return {
            "job_id": job_id,
            "state": job.state.name,
            "create_time": str(job.create_time),
            "update_time": str(job.update_time),
        }
    except Exception as e:
        raise HTTPException(status_code=404, detail=str(e))


# ===== Cloud Run å¸¸é§ç‰ˆ: pyannote.audio ã‚’å†…è”µ =====

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§pyannoteãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¿æŒ
pipeline = None

@app.on_event("startup")
async def startup_event():
    """èµ·å‹•æ™‚ã«pyannoteãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–ï¼ˆ1å›ã ã‘ï¼‰"""
    global pipeline
    print("ğŸš€ Initializing pyannote.audio pipeline...")
    
    try:
        from pyannote.audio import Pipeline
        import torch
        
        # Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
        token = HF_TOKEN_SECRET
        if not token:
            print("âš ï¸  HF_TOKEN not found, pipeline initialization skipped")
            return
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=token
        )
        
        # GPU/CPUè‡ªå‹•é¸æŠ
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        pipeline.to(device)
        
        print(f"âœ… Pipeline loaded on {device}")
        
    except Exception as e:
        print(f"âŒ Failed to initialize pipeline: {e}")
        pipeline = None


class ProcessLocalRequest(BaseModel):
    input_gs_uri: str
    output_gs_uri: Optional[str] = None
    use_gpu: bool = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯GPU


@app.post("/process-local")
async def process_local(request: ProcessLocalRequest):
    """Cloud Runå†…ã§ç›´æ¥å‡¦ç†ï¼ˆVertex AIä¸è¦ã€Jobå¾…ã¡ã‚¼ãƒ­ï¼‰"""
    if pipeline is None:
        raise HTTPException(status_code=503, detail="Pipeline not initialized")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼šuse_gpu ã®å€¤ã‚’ç¢ºèª
    print(f"ğŸ” DEBUG: process-local use_gpu = {request.use_gpu}")
    
    audio_path = None
    original_audio_path = None
    
    try:
        # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ‹¡å¼µå­ã‚’å–å¾—
        original_filename = request.input_gs_uri.split("/")[-1]
        file_extension = os.path.splitext(original_filename)[1] or ".wav"
        base_name = os.path.splitext(original_filename)[0]
        
        # å‡ºåŠ›å…ˆãŒæœªæŒ‡å®šãªã‚‰è‡ªå‹•ç”Ÿæˆ
        if not request.output_gs_uri:
            request.output_gs_uri = f"gs://{BUCKET}/outputs/{base_name}.json"
        
        print(f"ğŸ¯ Processing {request.input_gs_uri} locally...")
        print(f"ğŸ“ File format: {file_extension}")
        
        # 1. GCSã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        bucket = storage_client.bucket(BUCKET)
        blob_path = request.input_gs_uri.replace(f"gs://{BUCKET}/", "")
        blob = bucket.blob(blob_path)
        
        # 2. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆå…ƒã®æ‹¡å¼µå­ã‚’ä½¿ç”¨ï¼‰
        with tempfile.NamedTemporaryFile(suffix=file_extension, delete=False) as tmp_file:
            blob.download_to_filename(tmp_file.name)
            original_audio_path = tmp_file.name
        
        print(f"ğŸ“¥ Downloaded to {original_audio_path}")
        
        # 3. å¿…è¦ã«å¿œã˜ã¦wavã«å¤‰æ›
        if file_extension.lower() not in ['.wav', '.wave']:
            print(f"ğŸ”„ Converting {file_extension} to WAV...")
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as wav_file:
                wav_path = wav_file.name
            
            # ffmpegã§å¤‰æ›
            result_ffmpeg = subprocess.run(
                ['ffmpeg', '-i', original_audio_path, '-ar', '16000', '-ac', '1', wav_path, '-y'],
                capture_output=True,
                text=True
            )
            
            if result_ffmpeg.returncode != 0:
                print(f"âŒ FFmpeg error: {result_ffmpeg.stderr}")
                raise Exception(f"Failed to convert audio: {result_ffmpeg.stderr}")
            
            audio_path = wav_path
            print(f"âœ… Converted to {wav_path}")
        else:
            audio_path = original_audio_path
        
        # 4. GPU/CPUåˆ‡ã‚Šæ›¿ãˆ
        import torch
        target_device = torch.device("cuda" if request.use_gpu and torch.cuda.is_available() else "cpu")
        
        # ç¾åœ¨ã®ãƒ‡ãƒã‚¤ã‚¹ã‚’å®‰å…¨ã«å–å¾—
        try:
            current_device = next(iter(pipeline.parameters())).device
        except (StopIteration, TypeError, AttributeError):
            current_device = None
        
        print(f"ğŸ¯ Target device: {target_device}")
        print(f"ğŸ“ Current device: {current_device}")
        
        # ãƒ‡ãƒã‚¤ã‚¹ãŒç•°ãªã‚‹å ´åˆã¯ç§»å‹•ï¼ˆåˆå›ã¯Noneãªã®ã§å¿…ãšç§»å‹•ï¼‰
        if current_device is None or current_device != target_device:
            print(f"ğŸ”„ Moving pipeline to {target_device}...")
            pipeline.to(target_device)
        
        # 5. pyannote.audio ã§å‡¦ç†
        print(f"ğŸ™ï¸  Running speaker diarization on {target_device}...")
        diarization = pipeline(audio_path)
        
        # ãƒ‡ãƒãƒƒã‚°: diarizationã®å‹ã‚’ç¢ºèª
        print(f"ğŸ” DEBUG: diarization type = {type(diarization)}")
        print(f"ğŸ” DEBUG: diarization has itertracks = {hasattr(diarization, 'itertracks')}")
        print(f"ğŸ” DEBUG: diarization dir = {dir(diarization)}")
        
        # 6. çµæœã‚’æ•´å½¢
        result = []
        try:
            # æ¨™æº–çš„ãªæ–¹æ³•
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                result.append({
                    "start": turn.start,
                    "end": turn.end,
                    "speaker": speaker
                })
        except (TypeError, AttributeError) as e:
            print(f"âš ï¸  Standard iteration failed: {e}")
            print(f"ğŸ” Attempting alternative iteration...")
            
            # diarizationãŒdictã®å ´åˆã®å‡¦ç†
            if isinstance(diarization, dict):
                print(f"ğŸ” diarization is dict with keys: {diarization.keys()}")
                # dictã®å ´åˆã€ç›´æ¥ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒˆ
                if 'segments' in diarization:
                    for seg in diarization['segments']:
                        result.append(seg)
                else:
                    raise Exception(f"Unknown dict structure: {diarization}")
            else:
                # ãã®ä»–ã®å ´åˆ
                raise Exception(f"Cannot iterate over type {type(diarization)}: {e}")
        
        speaker_count = len(set(item["speaker"] for item in result))
        print(f"âœ… Found {speaker_count} speakers, {len(result)} segments")
        
        # 7. GCSã«çµæœã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        output_blob_path = request.output_gs_uri.replace(f"gs://{BUCKET}/", "")
        output_blob = bucket.blob(output_blob_path)
        output_blob.upload_from_string(
            json.dumps(result, indent=2),
            content_type="application/json"
        )
        
        # 8. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        os.unlink(audio_path)
        if audio_path != original_audio_path:
            os.unlink(original_audio_path)
        
        print(f"ğŸ“¤ Results uploaded to {request.output_gs_uri}")
        
        return {
            "status": "success",
            "output_gs_uri": request.output_gs_uri,
            "speaker_count": speaker_count,
            "segment_count": len(result)
        }
        
    except Exception as e:
        print(f"âŒ Error during processing: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        try:
            if audio_path:
                os.unlink(audio_path)
            if original_audio_path and audio_path != original_audio_path:
                os.unlink(original_audio_path)
        except:
            pass
        raise HTTPException(status_code=500, detail=str(e))
