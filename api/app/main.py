import os
import asyncio
import json
import tempfile
import subprocess
from datetime import timedelta
from typing import Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from google.cloud import storage, secretmanager

# ç’°å¢ƒå¤‰æ•°
PROJECT_ID = os.environ.get("PROJECT_ID", "encoded-victory-440718-k6")
REGION = os.environ.get("REGION", "us-west1")
BUCKET = os.environ.get("BUCKET", "audio-processing-studio")
HF_TOKEN_SECRET = os.environ.get("HF_TOKEN", "")

app = FastAPI(title="Meeting Audio Processing API")

# CORSè¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼šè¤‡æ•°ã‚ªãƒªã‚¸ãƒ³å¯¾å¿œï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001",
        "http://127.0.0.1:3001",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# GCS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
storage_client = storage.Client()


class SignUrlRequest(BaseModel):
    file_name: str
    content_type: str = "audio/wav"


@app.get("/health")
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "ok", "project": PROJECT_ID, "region": REGION}


@app.post("/sign-url")
async def create_signed_url(request: SignUrlRequest):
    """GCSç½²åURLã‚’ç™ºè¡Œï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ç›´ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰"""
    try:
        import json
        from google.oauth2 import service_account
        
        # Secret Managerã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/run-api-service-account-key/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        secret_data = response.payload.data.decode("UTF-8")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        service_account_info = json.loads(secret_data)
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èªè¨¼æƒ…å ±ä»˜ãã§ä½œæˆ
        storage_client_with_key = storage.Client(credentials=credentials, project=PROJECT_ID)
        bucket = storage_client_with_key.bucket(BUCKET)
        blob = bucket.blob(f"uploads/{request.file_name}")
        
        # PUTç”¨ã®ç½²åURLï¼ˆ10åˆ†æœ‰åŠ¹ï¼‰
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=10),
            method="PUT",
            content_type=request.content_type
        )
        
        return {
            "signed_url": url,
            "gs_uri": f"gs://{BUCKET}/uploads/{request.file_name}",
            "expires_in": 600
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class DownloadUrlRequest(BaseModel):
    gs_uri: str


@app.post("/download-url")
async def create_download_url(request: DownloadUrlRequest):
    """GCSç½²åãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’ç™ºè¡Œ"""
    try:
        import json
        from google.oauth2 import service_account
        
        # gs:// ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¦ãƒ‘ã‚¹ã‚’å–å¾—
        if not request.gs_uri.startswith(f"gs://{BUCKET}/"):
            raise HTTPException(status_code=400, detail="Invalid GCS URI")
        
        blob_path = request.gs_uri.replace(f"gs://{BUCKET}/", "")
        
        # Secret Managerã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/run-api-service-account-key/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        secret_data = response.payload.data.decode("UTF-8")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        service_account_info = json.loads(secret_data)
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èªè¨¼æƒ…å ±ä»˜ãã§ä½œæˆ
        storage_client_with_key = storage.Client(credentials=credentials, project=PROJECT_ID)
        bucket = storage_client_with_key.bucket(BUCKET)
        blob = bucket.blob(blob_path)
        
        # GETç”¨ã®ç½²åURLï¼ˆ10åˆ†æœ‰åŠ¹ï¼‰
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=10),
            method="GET"
        )
        
        return {
            "signed_url": url,
            "expires_in": 600
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ===== Cloud Run å¸¸é§ç‰ˆ: pyannote.audio ã‚’å†…è”µ =====

from collections import OrderedDict

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«å®šç¾©
AVAILABLE_MODELS = {
    "3.1": "pyannote/speaker-diarization-3.1",
    "community-1": "pyannote/speaker-diarization-community-1",
}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼šå‹•çš„ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
loaded_pipelines = OrderedDict()
MAX_LOADED_MODELS = 2  # åŒæ™‚ã«2å€‹ã¾ã§ãƒ¡ãƒ¢ãƒªã«è¼‰ã›ã‚‹
device = None

@app.on_event("startup")
async def startup_event():
    """èµ·å‹•æ™‚ã«ãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®š"""
    global device
    print("ğŸš€ Initializing pyannote.audio system...")
    
    try:
        import torch
        
        # Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºèª
        token = HF_TOKEN_SECRET
        if not token:
            print("âš ï¸  HF_TOKEN not found")
            return
        
        # GPU/CPUè‡ªå‹•é¸æŠ
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"âœ… Device set to {device}")
        print(f"ğŸ“‹ Available models: {list(AVAILABLE_MODELS.keys())}")
        print(f"ğŸ’¾ Max loaded models: {MAX_LOADED_MODELS}")
        
    except Exception as e:
        print(f"âŒ Failed to initialize: {e}")


def get_pipeline(model_name: str):
    """ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰ï¼‰"""
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ
    if model_name in loaded_pipelines:
        print(f"âœ… Using cached model: {model_name}")
        loaded_pipelines.move_to_end(model_name)  # LRU: æœ€æ–°ä½¿ç”¨ã¨ã—ã¦æ›´æ–°
        return loaded_pipelines[model_name]
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ â†’ ãƒ­ãƒ¼ãƒ‰
    return load_pipeline(model_name)


def load_pipeline(model_name: str):
    """æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰"""
    import torch
    from pyannote.audio import Pipeline
    
    # ãƒ¢ãƒ‡ãƒ«åã®æ¤œè¨¼
    if model_name not in AVAILABLE_MODELS:
        raise ValueError(f"Unknown model: {model_name}. Available: {list(AVAILABLE_MODELS.keys())}")
    
    # ãƒ¡ãƒ¢ãƒªãŒæº€æ¯ãªã‚‰æœ€ã‚‚å¤ã„ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤
    if len(loaded_pipelines) >= MAX_LOADED_MODELS:
        oldest_model = next(iter(loaded_pipelines))
        print(f"ğŸ—‘ï¸  Unloading least used model: {oldest_model}")
        del loaded_pipelines[oldest_model]
        
        # GPU/CPUãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        import gc
        gc.collect()
    
    # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    print(f"ğŸ“¦ Loading model: {model_name}...")
    model_path = AVAILABLE_MODELS[model_name]
    
    try:
        # pyannote.audio ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¿œã˜ã¦é©åˆ‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        print(f"ğŸ”„ Trying to load with use_auth_token...")
        try:
            pipeline = Pipeline.from_pretrained(model_path, use_auth_token=HF_TOKEN_SECRET)
        except TypeError:
            # use_auth_token ãŒä½¿ãˆãªã„å ´åˆã¯ token ã‚’è©¦ã™
            print(f"ğŸ”„ Retrying with token parameter...")
            pipeline = Pipeline.from_pretrained(model_path, token=HF_TOKEN_SECRET)
        
        pipeline.to(device)
        loaded_pipelines[model_name] = pipeline
        
        print(f"âœ… Model loaded: {model_name} (total loaded: {len(loaded_pipelines)})")
        return pipeline
        
    except Exception as e:
        print(f"âŒ Failed to load {model_name}: {e}")
        raise


class ProcessLocalRequest(BaseModel):
    input_gs_uri: str
    output_gs_uri: Optional[str] = None
    use_gpu: bool = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯GPU
    model: str = "3.1"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯3.1ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰


@app.post("/process-local")
async def process_local(request: ProcessLocalRequest):
    """Cloud Runå†…ã§ç›´æ¥å‡¦ç†ï¼ˆVertex AIä¸è¦ã€Jobå¾…ã¡ã‚¼ãƒ­ï¼‰"""
    # å‹•çš„ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å–å¾—
    try:
        pipeline = get_pipeline(request.model)
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Failed to load model '{request.model}': {str(e)}")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼šuse_gpu ã®å€¤ã‚’ç¢ºèª
    print(f"ğŸ” DEBUG: process-local use_gpu = {request.use_gpu}")
    
    audio_path = None
    original_audio_path = None
    
    try:
        # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ‹¡å¼µå­ã‚’å–å¾—
        original_filename = request.input_gs_uri.split("/")[-1]
        file_extension = os.path.splitext(original_filename)[1] or ".wav"
        base_name = os.path.splitext(original_filename)[0]
        
        # å‡ºåŠ›å…ˆãŒæœªæŒ‡å®šãªã‚‰è‡ªå‹•ç”Ÿæˆ
        if not request.output_gs_uri:
            request.output_gs_uri = f"gs://{BUCKET}/outputs/{base_name}.json"
        
        print(f"ğŸ¯ Processing {request.input_gs_uri} locally...")
        print(f"ğŸ“ File format: {file_extension}")
        
        # 1. GCSã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        bucket = storage_client.bucket(BUCKET)
        blob_path = request.input_gs_uri.replace(f"gs://{BUCKET}/", "")
        blob = bucket.blob(blob_path)
        
        # 2. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆå…ƒã®æ‹¡å¼µå­ã‚’ä½¿ç”¨ï¼‰
        with tempfile.NamedTemporaryFile(suffix=file_extension, delete=False) as tmp_file:
            blob.download_to_filename(tmp_file.name)
            original_audio_path = tmp_file.name
        
        print(f"ğŸ“¥ Downloaded to {original_audio_path}")
        
        # 3. å¿…è¦ã«å¿œã˜ã¦wavã«å¤‰æ›
        if file_extension.lower() not in ['.wav', '.wave']:
            print(f"ğŸ”„ Converting {file_extension} to WAV...")
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as wav_file:
                wav_path = wav_file.name
            
            # ffmpegã§å¤‰æ›
            result_ffmpeg = subprocess.run(
                ['ffmpeg', '-i', original_audio_path, '-ar', '16000', '-ac', '1', wav_path, '-y'],
                capture_output=True,
                text=True
            )
            
            if result_ffmpeg.returncode != 0:
                print(f"âŒ FFmpeg error: {result_ffmpeg.stderr}")
                raise Exception(f"Failed to convert audio: {result_ffmpeg.stderr}")
            
            audio_path = wav_path
            print(f"âœ… Converted to {wav_path}")
        else:
            audio_path = original_audio_path
        
        # 4. GPU/CPUåˆ‡ã‚Šæ›¿ãˆ
        import torch
        target_device = torch.device("cuda" if request.use_gpu and torch.cuda.is_available() else "cpu")
        
        # ç¾åœ¨ã®ãƒ‡ãƒã‚¤ã‚¹ã‚’å®‰å…¨ã«å–å¾—
        try:
            current_device = next(iter(pipeline.parameters())).device
        except (StopIteration, TypeError, AttributeError):
            current_device = None
        
        print(f"ğŸ¯ Target device: {target_device}")
        print(f"ğŸ“ Current device: {current_device}")
        
        # ãƒ‡ãƒã‚¤ã‚¹ãŒç•°ãªã‚‹å ´åˆã¯ç§»å‹•ï¼ˆåˆå›ã¯Noneãªã®ã§å¿…ãšç§»å‹•ï¼‰
        if current_device is None or current_device != target_device:
            print(f"ğŸ”„ Moving pipeline to {target_device}...")
            pipeline.to(target_device)
        
        # 5. pyannote.audio ã§å‡¦ç†
        print(f"ğŸ™ï¸  Running speaker diarization on {target_device}...")
        diarization = pipeline(audio_path)
        
        # ãƒ‡ãƒãƒƒã‚°: diarizationã®å‹ã‚’ç¢ºèª
        print(f"ğŸ” DEBUG: diarization type = {type(diarization)}")
        print(f"ğŸ” DEBUG: diarization has itertracks = {hasattr(diarization, 'itertracks')}")
        print(f"ğŸ” DEBUG: diarization dir = {dir(diarization)}")
        
        # 6. çµæœã‚’æ•´å½¢
        result = []
        try:
            # æ¨™æº–çš„ãªæ–¹æ³•
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                result.append({
                    "start": turn.start,
                    "end": turn.end,
                    "speaker": speaker
                })
        except (TypeError, AttributeError) as e:
            print(f"âš ï¸  Standard iteration failed: {e}")
            print(f"ğŸ” Attempting alternative iteration...")
            
            # diarizationãŒdictã®å ´åˆã®å‡¦ç†
            if isinstance(diarization, dict):
                print(f"ğŸ” diarization is dict with keys: {diarization.keys()}")
                # dictã®å ´åˆã€ç›´æ¥ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒˆ
                if 'segments' in diarization:
                    for seg in diarization['segments']:
                        result.append(seg)
                else:
                    raise Exception(f"Unknown dict structure: {diarization}")
            else:
                # ãã®ä»–ã®å ´åˆ
                raise Exception(f"Cannot iterate over type {type(diarization)}: {e}")
        
        speaker_count = len(set(item["speaker"] for item in result))
        print(f"âœ… Found {speaker_count} speakers, {len(result)} segments")
        
        # 7. GCSã«çµæœã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        output_blob_path = request.output_gs_uri.replace(f"gs://{BUCKET}/", "")
        output_blob = bucket.blob(output_blob_path)
        output_blob.upload_from_string(
            json.dumps(result, indent=2),
            content_type="application/json"
        )
        
        # 8. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        os.unlink(audio_path)
        if audio_path != original_audio_path:
            os.unlink(original_audio_path)
        
        print(f"ğŸ“¤ Results uploaded to {request.output_gs_uri}")
        
        return {
            "status": "success",
            "output_gs_uri": request.output_gs_uri,
            "speaker_count": speaker_count,
            "segment_count": len(result)
        }
        
    except Exception as e:
        print(f"âŒ Error during processing: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        try:
            if audio_path:
                os.unlink(audio_path)
            if original_audio_path and audio_path != original_audio_path:
                os.unlink(original_audio_path)
        except:
            pass
        raise HTTPException(status_code=500, detail=str(e))
