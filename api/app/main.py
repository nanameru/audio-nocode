import os
import asyncio
import json
import tempfile
import subprocess
from datetime import timedelta
from typing import Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from google.cloud import storage, secretmanager

# ç’°å¢ƒå¤‰æ•°
PROJECT_ID = os.environ.get("PROJECT_ID", "encoded-victory-440718-k6")
REGION = os.environ.get("REGION", "us-west1")
BUCKET = os.environ.get("BUCKET", "audio-processing-studio")
HF_TOKEN_SECRET = os.environ.get("HF_TOKEN", "")

app = FastAPI(title="Meeting Audio Processing API")

# CORSè¨­å®šï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼šè¤‡æ•°ã‚ªãƒªã‚¸ãƒ³å¯¾å¿œï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001",
        "http://127.0.0.1:3001",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# GCS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
storage_client = storage.Client()


class SignUrlRequest(BaseModel):
    file_name: str
    content_type: str = "audio/wav"


@app.get("/health")
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "ok", "project": PROJECT_ID, "region": REGION}


@app.post("/sign-url")
async def create_signed_url(request: SignUrlRequest):
    """GCSç½²åURLã‚’ç™ºè¡Œï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ç›´ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰"""
    try:
        import json
        from google.oauth2 import service_account
        
        # Secret Managerã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/run-api-service-account-key/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        secret_data = response.payload.data.decode("UTF-8")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        service_account_info = json.loads(secret_data)
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èªè¨¼æƒ…å ±ä»˜ãã§ä½œæˆ
        storage_client_with_key = storage.Client(credentials=credentials, project=PROJECT_ID)
        bucket = storage_client_with_key.bucket(BUCKET)
        blob = bucket.blob(f"uploads/{request.file_name}")
        
        # PUTç”¨ã®ç½²åURLï¼ˆ10åˆ†æœ‰åŠ¹ï¼‰
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=10),
            method="PUT",
            content_type=request.content_type
        )
        
        return {
            "signed_url": url,
            "gs_uri": f"gs://{BUCKET}/uploads/{request.file_name}",
            "expires_in": 600
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class DownloadUrlRequest(BaseModel):
    gs_uri: str


@app.post("/download-url")
async def create_download_url(request: DownloadUrlRequest):
    """GCSç½²åãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’ç™ºè¡Œ"""
    try:
        import json
        from google.oauth2 import service_account
        
        # gs:// ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¦ãƒ‘ã‚¹ã‚’å–å¾—
        if not request.gs_uri.startswith(f"gs://{BUCKET}/"):
            raise HTTPException(status_code=400, detail="Invalid GCS URI")
        
        blob_path = request.gs_uri.replace(f"gs://{BUCKET}/", "")
        
        # Secret Managerã‹ã‚‰ç§˜å¯†éµã‚’å–å¾—
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/run-api-service-account-key/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        secret_data = response.payload.data.decode("UTF-8")
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        service_account_info = json.loads(secret_data)
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èªè¨¼æƒ…å ±ä»˜ãã§ä½œæˆ
        storage_client_with_key = storage.Client(credentials=credentials, project=PROJECT_ID)
        bucket = storage_client_with_key.bucket(BUCKET)
        blob = bucket.blob(blob_path)
        
        # GETç”¨ã®ç½²åURLï¼ˆ10åˆ†æœ‰åŠ¹ï¼‰
        url = blob.generate_signed_url(
            version="v4",
            expiration=timedelta(minutes=10),
            method="GET"
        )
        
        return {
            "signed_url": url,
            "expires_in": 600
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ===== Cloud Run å¸¸é§ç‰ˆ: pyannote.audio ã‚’å†…è”µ =====

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§pyannoteãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¿æŒ
pipeline = None

@app.on_event("startup")
async def startup_event():
    """èµ·å‹•æ™‚ã«pyannoteãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–ï¼ˆ1å›ã ã‘ï¼‰"""
    global pipeline
    print("ğŸš€ Initializing pyannote.audio pipeline...")
    
    try:
        from pyannote.audio import Pipeline
        import torch
        
        # Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
        token = HF_TOKEN_SECRET
        if not token:
            print("âš ï¸  HF_TOKEN not found, pipeline initialization skipped")
            return
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=token
        )
        
        # GPU/CPUè‡ªå‹•é¸æŠ
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        pipeline.to(device)
        
        print(f"âœ… Pipeline loaded on {device}")
        
    except Exception as e:
        print(f"âŒ Failed to initialize pipeline: {e}")
        pipeline = None


class ProcessLocalRequest(BaseModel):
    input_gs_uri: str
    output_gs_uri: Optional[str] = None
    use_gpu: bool = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯GPU


@app.post("/process-local")
async def process_local(request: ProcessLocalRequest):
    """Cloud Runå†…ã§ç›´æ¥å‡¦ç†ï¼ˆVertex AIä¸è¦ã€Jobå¾…ã¡ã‚¼ãƒ­ï¼‰"""
    if pipeline is None:
        raise HTTPException(status_code=503, detail="Pipeline not initialized")
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼šuse_gpu ã®å€¤ã‚’ç¢ºèª
    print(f"ğŸ” DEBUG: process-local use_gpu = {request.use_gpu}")
    
    audio_path = None
    original_audio_path = None
    
    try:
        # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ‹¡å¼µå­ã‚’å–å¾—
        original_filename = request.input_gs_uri.split("/")[-1]
        file_extension = os.path.splitext(original_filename)[1] or ".wav"
        base_name = os.path.splitext(original_filename)[0]
        
        # å‡ºåŠ›å…ˆãŒæœªæŒ‡å®šãªã‚‰è‡ªå‹•ç”Ÿæˆ
        if not request.output_gs_uri:
            request.output_gs_uri = f"gs://{BUCKET}/outputs/{base_name}.json"
        
        print(f"ğŸ¯ Processing {request.input_gs_uri} locally...")
        print(f"ğŸ“ File format: {file_extension}")
        
        # 1. GCSã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        bucket = storage_client.bucket(BUCKET)
        blob_path = request.input_gs_uri.replace(f"gs://{BUCKET}/", "")
        blob = bucket.blob(blob_path)
        
        # 2. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆå…ƒã®æ‹¡å¼µå­ã‚’ä½¿ç”¨ï¼‰
        with tempfile.NamedTemporaryFile(suffix=file_extension, delete=False) as tmp_file:
            blob.download_to_filename(tmp_file.name)
            original_audio_path = tmp_file.name
        
        print(f"ğŸ“¥ Downloaded to {original_audio_path}")
        
        # 3. å¿…è¦ã«å¿œã˜ã¦wavã«å¤‰æ›
        if file_extension.lower() not in ['.wav', '.wave']:
            print(f"ğŸ”„ Converting {file_extension} to WAV...")
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as wav_file:
                wav_path = wav_file.name
            
            # ffmpegã§å¤‰æ›
            result_ffmpeg = subprocess.run(
                ['ffmpeg', '-i', original_audio_path, '-ar', '16000', '-ac', '1', wav_path, '-y'],
                capture_output=True,
                text=True
            )
            
            if result_ffmpeg.returncode != 0:
                print(f"âŒ FFmpeg error: {result_ffmpeg.stderr}")
                raise Exception(f"Failed to convert audio: {result_ffmpeg.stderr}")
            
            audio_path = wav_path
            print(f"âœ… Converted to {wav_path}")
        else:
            audio_path = original_audio_path
        
        # 4. GPU/CPUåˆ‡ã‚Šæ›¿ãˆ
        import torch
        target_device = torch.device("cuda" if request.use_gpu and torch.cuda.is_available() else "cpu")
        
        # ç¾åœ¨ã®ãƒ‡ãƒã‚¤ã‚¹ã‚’å®‰å…¨ã«å–å¾—
        try:
            current_device = next(iter(pipeline.parameters())).device
        except (StopIteration, TypeError, AttributeError):
            current_device = None
        
        print(f"ğŸ¯ Target device: {target_device}")
        print(f"ğŸ“ Current device: {current_device}")
        
        # ãƒ‡ãƒã‚¤ã‚¹ãŒç•°ãªã‚‹å ´åˆã¯ç§»å‹•ï¼ˆåˆå›ã¯Noneãªã®ã§å¿…ãšç§»å‹•ï¼‰
        if current_device is None or current_device != target_device:
            print(f"ğŸ”„ Moving pipeline to {target_device}...")
            pipeline.to(target_device)
        
        # 5. pyannote.audio ã§å‡¦ç†
        print(f"ğŸ™ï¸  Running speaker diarization on {target_device}...")
        diarization = pipeline(audio_path)
        
        # ãƒ‡ãƒãƒƒã‚°: diarizationã®å‹ã‚’ç¢ºèª
        print(f"ğŸ” DEBUG: diarization type = {type(diarization)}")
        print(f"ğŸ” DEBUG: diarization has itertracks = {hasattr(diarization, 'itertracks')}")
        print(f"ğŸ” DEBUG: diarization dir = {dir(diarization)}")
        
        # 6. çµæœã‚’æ•´å½¢
        result = []
        try:
            # æ¨™æº–çš„ãªæ–¹æ³•
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                result.append({
                    "start": turn.start,
                    "end": turn.end,
                    "speaker": speaker
                })
        except (TypeError, AttributeError) as e:
            print(f"âš ï¸  Standard iteration failed: {e}")
            print(f"ğŸ” Attempting alternative iteration...")
            
            # diarizationãŒdictã®å ´åˆã®å‡¦ç†
            if isinstance(diarization, dict):
                print(f"ğŸ” diarization is dict with keys: {diarization.keys()}")
                # dictã®å ´åˆã€ç›´æ¥ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒˆ
                if 'segments' in diarization:
                    for seg in diarization['segments']:
                        result.append(seg)
                else:
                    raise Exception(f"Unknown dict structure: {diarization}")
            else:
                # ãã®ä»–ã®å ´åˆ
                raise Exception(f"Cannot iterate over type {type(diarization)}: {e}")
        
        speaker_count = len(set(item["speaker"] for item in result))
        print(f"âœ… Found {speaker_count} speakers, {len(result)} segments")
        
        # 7. GCSã«çµæœã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        output_blob_path = request.output_gs_uri.replace(f"gs://{BUCKET}/", "")
        output_blob = bucket.blob(output_blob_path)
        output_blob.upload_from_string(
            json.dumps(result, indent=2),
            content_type="application/json"
        )
        
        # 8. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        os.unlink(audio_path)
        if audio_path != original_audio_path:
            os.unlink(original_audio_path)
        
        print(f"ğŸ“¤ Results uploaded to {request.output_gs_uri}")
        
        return {
            "status": "success",
            "output_gs_uri": request.output_gs_uri,
            "speaker_count": speaker_count,
            "segment_count": len(result)
        }
        
    except Exception as e:
        print(f"âŒ Error during processing: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        try:
            if audio_path:
                os.unlink(audio_path)
            if original_audio_path and audio_path != original_audio_path:
                os.unlink(original_audio_path)
        except:
            pass
        raise HTTPException(status_code=500, detail=str(e))
