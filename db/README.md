# Audio Processing Studio - Database Schema

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€Supabaseç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹æˆ

### **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®é–¢ä¿‚:**
```
audio_files (éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«)
    â†“
workflow_executions (å®Ÿè¡Œå±¥æ­´) â† workflows (ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©)
    â†“
â”œâ”€â”€ execution_logs (ãƒ­ã‚°)
â””â”€â”€ execution_results (çµæœ)
```

---

### 1. `workflows` - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è¨­å®šã‚’ä¿å­˜ã—ã¾ã™ã€‚

| ã‚«ãƒ©ãƒ å | å‹ | èª¬æ˜ |
|---------|-----|------|
| id | UUID | ä¸»ã‚­ãƒ¼ |
| name | TEXT | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å |
| description | TEXT | èª¬æ˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |
| pipeline_data | JSONB | ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®JSONï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€æ¥ç¶šãªã©ï¼‰ |
| created_at | TIMESTAMPTZ | ä½œæˆæ—¥æ™‚ |
| updated_at | TIMESTAMPTZ | æ›´æ–°æ—¥æ™‚ |

**ä¿å­˜ã•ã‚Œã‚‹JSONã®ä¾‹:**
```json
{
  "modules": [
    {
      "id": "input-1",
      "name": "Audio Input",
      "type": "input",
      "definitionId": "audio-input",
      "position": { "x": 100, "y": 100 },
      "parameters": {}
    },
    {
      "id": "pyannote-1",
      "name": "pyannote 3.1",
      "type": "diarization",
      "definitionId": "pyannote-diarization-3.1",
      "position": { "x": 400, "y": 100 },
      "parameters": {
        "min_speakers": 2,
        "max_speakers": 10
      }
    }
  ],
  "connections": [
    {
      "id": "conn-1",
      "source": "input-1",
      "target": "pyannote-1",
      "sourcePort": "output",
      "targetPort": "input"
    }
  ]
}
```

---

### 2. `audio_files` - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™ã€‚

| ã‚«ãƒ©ãƒ å | å‹ | èª¬æ˜ |
|---------|-----|------|
| id | UUID | ä¸»ã‚­ãƒ¼ |
| filename | TEXT | GCSä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«å |
| original_filename | TEXT | å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«å |
| gs_uri | TEXT | GCS URI |
| file_size_bytes | BIGINT | ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰ |
| duration_seconds | DECIMAL | éŸ³å£°ã®é•·ã•ï¼ˆç§’ï¼‰ |
| format | TEXT | ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ï¼ˆwav, mp3ãªã©ï¼‰ |
| sample_rate | INTEGER | ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆHzï¼‰ |
| channels | INTEGER | ãƒãƒ£ãƒ³ãƒãƒ«æ•° |
| uploaded_at | TIMESTAMPTZ | ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ—¥æ™‚ |
| created_at | TIMESTAMPTZ | ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚ |

**ä¾‹:**
```sql
INSERT INTO audio_files (
  filename, 
  original_filename, 
  gs_uri, 
  file_size_bytes, 
  duration_seconds, 
  format, 
  sample_rate, 
  channels
)
VALUES (
  'sample_20250106_123456.wav',
  'meeting_recording.wav',
  'gs://audio-processing-studio/uploads/sample_20250106_123456.wav',
  15728640,
  300.5,
  'wav',
  16000,
  1
);
```

---

### 3. `workflow_executions` - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå±¥æ­´
ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®å®Ÿè¡Œã‚’1ã¤ã®å˜ä½ã¨ã—ã¦ç®¡ç†ã—ã¾ã™ã€‚

| ã‚«ãƒ©ãƒ å | å‹ | èª¬æ˜ |
|---------|-----|------|
| id | UUID | ä¸»ã‚­ãƒ¼ |
| workflow_id | UUID | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼IDï¼ˆå¤–éƒ¨ã‚­ãƒ¼ï¼‰ |
| audio_file_id | UUID | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«IDï¼ˆå¤–éƒ¨ã‚­ãƒ¼ï¼‰ |
| status | TEXT | å®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |
| started_at | TIMESTAMPTZ | å®Ÿè¡Œé–‹å§‹æ—¥æ™‚ |
| completed_at | TIMESTAMPTZ | å®Ÿè¡Œå®Œäº†æ—¥æ™‚ |
| total_duration_ms | INTEGER | ç·å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰ |
| error_message | TEXT | ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ |
| metadata | JSONB | è¿½åŠ æƒ…å ± |
| created_at | TIMESTAMPTZ | ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚ |

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** `pending`, `running`, `completed`, `failed`, `cancelled`

**ä¾‹:**
```typescript
// ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’é–‹å§‹
const { data: execution } = await supabase
  .rpc('start_workflow_execution', {
    p_workflow_id: workflowId,
    p_audio_file_id: audioFileId
  });

// å®Ÿè¡Œã‚’å®Œäº†
await supabase
  .rpc('complete_workflow_execution', {
    p_execution_id: execution.id,
    p_status: 'completed'
  });
```

---

### 4. `execution_logs` - å®Ÿè¡Œãƒ­ã‚°
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œæ™‚ã®ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã™ã€‚

| ã‚«ãƒ©ãƒ å | å‹ | èª¬æ˜ |
|---------|-----|------|
| id | UUID | ä¸»ã‚­ãƒ¼ |
| workflow_id | UUID | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼IDï¼ˆå¤–éƒ¨ã‚­ãƒ¼ï¼‰ |
| level | TEXT | ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ï¼ˆinfo/success/warning/errorï¼‰ |
| message | TEXT | ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ |
| details | TEXT | è©³ç´°æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |
| module_name | TEXT | é–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |
| timestamp | TIMESTAMPTZ | ãƒ­ã‚°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— |
| created_at | TIMESTAMPTZ | ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚ |

**ä¾‹:**
```sql
INSERT INTO execution_logs (workflow_id, level, message, module_name, timestamp)
VALUES (
  '550e8400-e29b-41d4-a716-446655440000',
  'info',
  'ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã—ãŸ',
  'Audio Input',
  NOW()
);
```

---

### 5. `execution_results` - å®Ÿè¡Œçµæœ
ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè¡Œçµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚

| ã‚«ãƒ©ãƒ å | å‹ | èª¬æ˜ |
|---------|-----|------|
| id | UUID | ä¸»ã‚­ãƒ¼ |
| workflow_id | UUID | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼IDï¼ˆå¤–éƒ¨ã‚­ãƒ¼ï¼‰ |
| module_id | UUID | ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ID |
| module_name | TEXT | ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å |
| status | TEXT | å®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆsuccess/errorï¼‰ |
| output_gs_uri | TEXT | GCS URIï¼ˆçµæœãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ |
| speaker_count | INTEGER | æ¤œå‡ºã•ã‚ŒãŸè©±è€…æ•° |
| segment_count | INTEGER | ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•° |
| error_message | TEXT | ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰ |
| execution_time_ms | INTEGER | å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰ |
| result_data | JSONB | è¿½åŠ ã®çµæœãƒ‡ãƒ¼ã‚¿ |
| created_at | TIMESTAMPTZ | ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚ |

**ä¾‹:**
```sql
INSERT INTO execution_results (
  workflow_id, 
  module_id, 
  module_name, 
  status, 
  output_gs_uri, 
  speaker_count, 
  segment_count
)
VALUES (
  '550e8400-e29b-41d4-a716-446655440000',
  'pyannote-1',
  'pyannote 3.1',
  'success',
  'gs://audio-processing-studio/outputs/result.json',
  10,
  848
);
```

---

## ğŸš€ Supabaseã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### ã‚¹ãƒ†ãƒƒãƒ—1: Supabaseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ

1. [Supabase](https://supabase.com/)ã«ã‚¢ã‚¯ã‚»ã‚¹
2. æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: `audio-processing-studio`
4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®šï¼ˆä¿ç®¡ã—ã¦ãŠãï¼‰
5. ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é¸æŠï¼ˆæ¨å¥¨: Tokyo - Northeast Asiaï¼‰

### ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ¼ãƒã®é©ç”¨

1. Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’é–‹ã
2. å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ **SQL Editor** ã‚’é¸æŠ
3. `db/migrations/001_initial_schema.sql` ã®å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼
4. SQLã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ã«è²¼ã‚Šä»˜ã‘
5. **Run** ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯

### ã‚¹ãƒ†ãƒƒãƒ—3: æ¥ç¶šæƒ…å ±ã®å–å¾—

1. å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ **Settings** â†’ **API** ã‚’é¸æŠ
2. ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚³ãƒ”ãƒ¼ï¼š
   - **Project URL**: `https://xxxxx.supabase.co`
   - **anon public key**: `eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...`
   - **service_role key**: `eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...`

### ã‚¹ãƒ†ãƒƒãƒ—4: ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

`.env.local`ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```bash
# Supabase
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

---

## ğŸ“ ä½¿ç”¨ä¾‹

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¿å­˜

```typescript
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
);

// ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä¿å­˜
const { data, error } = await supabase
  .from('workflows')
  .insert({
    name: 'My Diarization Workflow',
    description: 'è©±è€…åˆ†é›¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼',
    pipeline_data: {
      modules: [...],
      connections: [...]
    }
  })
  .select()
  .single();
```

### å®Ÿè¡Œãƒ­ã‚°ã®è¿½åŠ 

```typescript
// ãƒ­ã‚°ã‚’è¿½åŠ 
await supabase
  .from('execution_logs')
  .insert({
    workflow_id: workflowId,
    level: 'info',
    message: 'Processing started',
    module_name: 'Audio Input',
    timestamp: new Date().toISOString()
  });
```

### å®Ÿè¡Œçµæœã®ä¿å­˜

```typescript
// çµæœã‚’ä¿å­˜
await supabase
  .from('execution_results')
  .insert({
    workflow_id: workflowId,
    module_id: 'pyannote-1',
    module_name: 'pyannote 3.1',
    status: 'success',
    output_gs_uri: 'gs://bucket/output.json',
    speaker_count: 10,
    segment_count: 848
  });
```

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸€è¦§ã®å–å¾—

```typescript
// ã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å–å¾—
const { data: workflows } = await supabase
  .from('workflows')
  .select('*')
  .order('updated_at', { ascending: false });
```

### å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®å–å¾—

```typescript
// ã‚µãƒãƒªãƒ¼ãƒ“ãƒ¥ãƒ¼ã‚’ä½¿ç”¨
const { data: summary } = await supabase
  .from('workflow_execution_summary')
  .select('*');
```

---

## ğŸ” ä¾¿åˆ©ãªã‚¯ã‚¨ãƒª

### æœ€æ–°ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼10ä»¶

```sql
SELECT id, name, description, updated_at
FROM workflows
ORDER BY updated_at DESC
LIMIT 10;
```

### ç‰¹å®šãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œå±¥æ­´

```sql
SELECT 
  er.created_at,
  er.module_name,
  er.status,
  er.speaker_count,
  er.segment_count
FROM execution_results er
WHERE er.workflow_id = '550e8400-e29b-41d4-a716-446655440000'
ORDER BY er.created_at DESC;
```

### ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç¢ºèª

```sql
SELECT 
  el.timestamp,
  el.message,
  el.details,
  el.module_name,
  w.name AS workflow_name
FROM execution_logs el
JOIN workflows w ON el.workflow_id = w.id
WHERE el.level = 'error'
ORDER BY el.timestamp DESC
LIMIT 50;
```

---

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

ç¾åœ¨ã¯Row Level Security (RLS)ã‚’ç„¡åŠ¹ã«ã—ã¦ã„ã¾ã™ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ãªã—ï¼‰ã€‚

å°†æ¥çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã€`001_initial_schema.sql`ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚ŒãŸRLSãƒãƒªã‚·ãƒ¼ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

---

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [Supabase Documentation](https://supabase.com/docs)
- [Supabase JavaScript Client](https://supabase.com/docs/reference/javascript/introduction)
- [PostgreSQL JSONB](https://www.postgresql.org/docs/current/datatype-json.html)

