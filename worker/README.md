# Audio Processing Worker

pyannote 3.1ã‚’ä½¿ã£ãŸè©±è€…åˆ†é›¢ï¼ˆDiarizationï¼‰ãƒ¯ãƒ¼ã‚«ãƒ¼

## CPU/GPUå¯¾å¿œ

ã“ã®Workerã¯CPUã¨GPUä¸¡æ–¹ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

### è‡ªå‹•æ¤œå‡ºæ©Ÿèƒ½

- Workerèµ·å‹•æ™‚ã«`torch.cuda.is_available()`ã§è‡ªå‹•åˆ¤å®š
- GPUåˆ©ç”¨å¯èƒ½ â†’ GPUä½¿ç”¨
- GPUåˆ©ç”¨ä¸å¯ â†’ CPUä½¿ç”¨

### Dockerã‚¤ãƒ¡ãƒ¼ã‚¸

#### GPUç‰ˆï¼ˆDockerfileï¼‰
```bash
# GPUç‰ˆã‚’ãƒ“ãƒ«ãƒ‰ï¼†ãƒ—ãƒƒã‚·ãƒ¥
./build-gpu.sh
```

- ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸: `nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04`
- PyTorch: CUDA 12.1å¯¾å¿œç‰ˆ
- ç”¨é€”: Vertex AI GPU ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆNVIDIA_TESLA_T4ï¼‰

#### CPUç‰ˆï¼ˆDockerfile.cpuï¼‰
```bash
# CPUç‰ˆã‚’ãƒ“ãƒ«ãƒ‰ï¼†ãƒ—ãƒƒã‚·ãƒ¥
./build-cpu.sh
```

- ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸: `python:3.10-slim`
- PyTorch: CPUå°‚ç”¨ç‰ˆï¼ˆè»½é‡ï¼‰
- ç”¨é€”: Vertex AI CPU ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

## ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹æ³•

### 1. Artifact Registryã«ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ

```bash
gcloud artifacts repositories create audio-processing \
  --repository-format=docker \
  --location=us-west1 \
  --project=encoded-victory-440718-k6
```

### 2. ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ï¼†ãƒ—ãƒƒã‚·ãƒ¥

```bash
# GPUç‰ˆ
cd worker
./build-gpu.sh

# CPUç‰ˆ
./build-cpu.sh
```

### 3. Cloud Run APIã«ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š

```bash
gcloud run services update meeting-api \
  --set-env-vars="WORKER_IMAGE_URI_GPU=us-west1-docker.pkg.dev/encoded-victory-440718-k6/audio-processing/worker-gpu:latest" \
  --set-env-vars="WORKER_IMAGE_URI_CPU=us-west1-docker.pkg.dev/encoded-victory-440718-k6/audio-processing/worker-cpu:latest" \
  --region=asia-northeast1
```

## ä½¿ç”¨æ–¹æ³•

### APIçµŒç”±ã§ã®å®Ÿè¡Œ

```bash
# GPUä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
curl -X POST https://your-api.run.app/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "input_gs_uri": "gs://bucket/input.wav",
    "use_gpu": true
  }'

# CPUä½¿ç”¨
curl -X POST https://your-api.run.app/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "input_gs_uri": "gs://bucket/input.wav",
    "use_gpu": false
  }'
```

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒˆã‚°ãƒ«

UIã®ã€ŒGPUä½¿ç”¨ã€ãƒˆã‚°ãƒ«ã‚’ã‚ªãƒ•ã«ã™ã‚‹ã¨ã€CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

- **GPUãƒ¢ãƒ¼ãƒ‰**: é«˜é€Ÿã ãŒã€GPUæ–™é‡‘ãŒã‹ã‹ã‚‹
- **CPUãƒ¢ãƒ¼ãƒ‰**: é…ã„ãŒã€æ–™é‡‘ãŒå®‰ã„

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å‡¦ç†ãŒæ­¢ã¾ã‚‹å ´åˆ

1. **ãƒ­ã‚°ã‚’ç¢ºèª**
   ```bash
   # Vertex AIã‚¸ãƒ§ãƒ–ã®ãƒ­ã‚°ã‚’ç¢ºèª
   gcloud ai custom-jobs stream-logs <JOB_ID> \
     --project=encoded-victory-440718-k6 \
     --region=us-west1
   ```

2. **ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª**
   - ãƒ­ã‚°ã« `ğŸ–¥ï¸ Using device: cpu` ã¾ãŸã¯ `ğŸ–¥ï¸ Using device: cuda:0` ãŒå‡ºåŠ›ã•ã‚Œã‚‹
   - CPUãƒ¢ãƒ¼ãƒ‰ãªã®ã«GPUã‚’ä½¿ãŠã†ã¨ã—ã¦ã„ãªã„ã‹ç¢ºèª

3. **ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ç¢ºèª**
   - APIãƒ­ã‚°ã§ `ğŸ“¦ Using image: ...` ã‚’ç¢ºèª
   - CPU/GPUã§é©åˆ‡ãªã‚¤ãƒ¡ãƒ¼ã‚¸ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### GPUç‰ˆãŒCPUã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å‹•ã‹ãªã„
â†’ `WORKER_IMAGE_URI_CPU` ã‚’è¨­å®šã—ã¦ãã ã•ã„

#### CPUç‰ˆãŒé…ã™ãã‚‹
â†’ `use_gpu: true` ã§GPUç‰ˆã‚’ä½¿ã£ã¦ãã ã•ã„

#### CUDA out of memory
â†’ GPUç‰ˆã§ã‚‚ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆã¯ã€ãƒã‚·ãƒ³ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã™ã‚‹ã‹ã€CPUç‰ˆã‚’ä½¿ç”¨

## ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆï¼ˆCPUç‰ˆï¼‰
docker build -f Dockerfile.cpu -t worker-cpu .
docker run --rm \
  -e MEETING_HF_TOKEN=your_hf_token \
  worker-cpu \
  --input gs://bucket/input.wav \
  --output gs://bucket/output.json
```

## å‚è€ƒ

- [pyannote.audio](https://github.com/pyannote/pyannote-audio)
- [Vertex AI Custom Jobs](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)
